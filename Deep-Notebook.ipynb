{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import show, plot_images, plot_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from skimage.measure import compare_psnr\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "EPOCHS = 2\n",
    "BATCH_SIZE = 20\n",
    "LEARNING_RATE = 0.003\n",
    "TRAIN_DATA_PATH = \"./Confocal_BPAE_B/raw\"\n",
    "GT_DATA_PATH = \"./Confocal_BPAE_B/gt\"\n",
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "    \n",
    "    ])\n",
    "train_data = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=TRANSFORM_IMG)\n",
    "gt_data = torchvision.datasets.ImageFolder(root=GT_DATA_PATH, transform=TRANSFORM_IMG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = train_data\n",
    "dataset2 = gt_data\n",
    "\n",
    "\n",
    "class gtmatch(Dataset):\n",
    "    def __init__(self, dataset1, dataset2, batch_size):\n",
    "        self.dataset1 = dataset1\n",
    "        self.dataset2 = dataset2\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.dataset1[index][0]\n",
    "        y= self.dataset2[int(index/batch_size % batch_size)][0]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset1)\n",
    "\n",
    "newdataset = gtmatch(dataset1, dataset2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=50\n",
    "from torch import randn\n",
    "def add_noise(img):\n",
    "    return img + randn(img.size())*0.05\n",
    "\n",
    "class SyntheticNoiseDataset(Dataset):\n",
    "    def __init__(self, data, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index][0]\n",
    "        return add_noise(img), img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_data_train = SyntheticNoiseDataset(train_data, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy,clean=newdataset[61]\n",
    "plot_tensors([noisy[0], clean[0]], ['Noisy Image', 'Clean Image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask import Masker\n",
    "masker = Masker(width = 4, mode='interpolate')\n",
    "net_input, mask = masker.mask(noisy.unsqueeze(0), 3)\n",
    "plot_tensors([mask, noisy[0], net_input[0], net_input[0] - noisy[0]],\n",
    "            [\"Mask\", \"Noisy Image\", \"Neural Net Input\", \"Difference\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models/models.babyunet import BabyUnet\n",
    "\n",
    "model = BabyUnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import logging \n",
    "loss_function = MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=800\n",
    "t=1000\n",
    "split=torch.utils.data.random_split(newdataset, [n,t-n]);\n",
    "train=split[0];\n",
    "test=split[1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask import Masker\n",
    "\n",
    "data_loader = DataLoader(train, batch_size=50, shuffle=True)\n",
    "\n",
    "#noisy, clean = noisy_data_train[0];\n",
    "#net_input, mask = masker.mask(noisy.unsqueeze(0), 0);\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "best_images = []\n",
    "best_val_loss = 1\n",
    "\n",
    "for i, batch in enumerate(data_loader):\n",
    "    noisy_images, clean_images = batch\n",
    "    \n",
    "    model.train()\n",
    " \n",
    "    net_input, mask = masker.mask(noisy_images, i)\n",
    "    net_output = model(net_input)\n",
    "    \n",
    "    loss = loss_function(net_output*mask, noisy_images*mask)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    " \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    model.eval()\n",
    "    \n",
    "\n",
    "    net_input, mask = masker.mask(noisy_images, masker.n_masks - 1)\n",
    "    net_output = model(net_input)\n",
    "\n",
    "    val_loss = loss_function(net_output*mask, noisy_images*mask)\n",
    "\n",
    "    val_losses.append(val_loss.item())\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Loss (\", i, \"): \\t\", round(loss.item(), 4))\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        denoised = np.clip(model(noisy_images).detach().cpu().numpy()[0, 0], 0, 1).astype(np.float64)\n",
    "        clean=np.clip(clean_images.detach().cpu().numpy()[0, 0], 0, 1).astype(np.float64)\n",
    "        best_psnr = compare_psnr(denoised, clean)\n",
    "        best_images.append(denoised)\n",
    "        print(\"\\tModel PSNR: \", np.round(best_psnr, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = DataLoader(test,\n",
    "                                              batch_size=50,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=3)\n",
    "i, test_batch = next(enumerate(test_data_loader))\n",
    "noisy, clean = test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_output = model(noisy)\n",
    "invariant_output = masker.infer_full_image(noisy, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 19\n",
    "plot_tensors([clean[idx], noisy[idx], simple_output[idx], invariant_output[idx]],\n",
    "            [\"Ground Truth\", \"Noisy Image\", \"Single Pass Inference\", \"J-Invariant Inference\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test loss, single pass: \", round(loss_function(clean, simple_output).item(), 3))\n",
    "print(\"Test loss, J-invariant: \", round(loss_function(clean, invariant_output).item(), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
