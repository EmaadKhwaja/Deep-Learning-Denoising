{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import show, plot_images, plot_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from skimage.measure import compare_psnr\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "EPOCHS = 2\n",
    "BATCH_SIZE = 20\n",
    "LEARNING_RATE = 0.003\n",
    "TRAIN_DATA_PATH = \"./Confocal_BPAE_B/raw\"\n",
    "GT_DATA_PATH = \"./Confocal_BPAE_B/gt\"\n",
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "    \n",
    "    ])\n",
    "train_data = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=TRANSFORM_IMG)\n",
    "gt_data = torchvision.datasets.ImageFolder(root=GT_DATA_PATH, transform=TRANSFORM_IMG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = train_data\n",
    "dataset2 = gt_data\n",
    "\n",
    "\n",
    "class gtmatch(Dataset):\n",
    "    def __init__(self, dataset1, dataset2, batch_size):\n",
    "        self.dataset1 = dataset1\n",
    "        self.dataset2 = dataset2\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.dataset1[index][0]\n",
    "        y= self.dataset2[int(index/batch_size % batch_size)][0]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset1)\n",
    "\n",
    "newdataset = gtmatch(dataset1, dataset2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=50\n",
    "from torch import randn\n",
    "def add_noise(img):\n",
    "    return img + randn(img.size())*0.05\n",
    "\n",
    "class SyntheticNoiseDataset(Dataset):\n",
    "    def __init__(self, data, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index][0]\n",
    "        return add_noise(img), img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_data_train = SyntheticNoiseDataset(train_data, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy,clean=newdataset[61]\n",
    "plot_tensors([noisy[0], clean[0]], ['Noisy Image', 'Clean Image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask import Masker\n",
    "masker = Masker(width = 4, mode='interpolate')\n",
    "net_input, mask = masker.mask(noisy.unsqueeze(0), 3)\n",
    "plot_tensors([mask, noisy[0], net_input[0], net_input[0] - noisy[0]],\n",
    "            [\"Mask\", \"Noisy Image\", \"Neural Net Input\", \"Difference\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.babyunet import BabyUnet\n",
    "\n",
    "model = BabyUnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import logging \n",
    "loss_function = MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=800\n",
    "t=1000\n",
    "split=torch.utils.data.random_split(newdataset, [n,t-n]);\n",
    "train=split[0];\n",
    "test=split[1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask import Masker\n",
    "\n",
    "data_loader = DataLoader(train, batch_size=50, shuffle=True)\n",
    "\n",
    "#noisy, clean = noisy_data_train[0];\n",
    "#net_input, mask = masker.mask(noisy.unsqueeze(0), 0);\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "best_images = []\n",
    "best_val_loss = 1\n",
    "\n",
    "for i, batch in enumerate(data_loader):\n",
    "    noisy_images, clean_images = batch\n",
    "    \n",
    "    model.train()\n",
    " \n",
    "    net_input, mask = masker.mask(noisy_images, i)\n",
    "    net_output = model(net_input)\n",
    "    \n",
    "    loss = loss_function(net_output*mask, noisy_images*mask)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    " \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    model.eval()\n",
    "    \n",
    "\n",
    "    net_input, mask = masker.mask(noisy_images, masker.n_masks - 1)\n",
    "    net_output = model(net_input)\n",
    "\n",
    "    val_loss = loss_function(net_output*mask, noisy_images*mask)\n",
    "\n",
    "    val_losses.append(val_loss.item())\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Loss (\", i, \"): \\t\", round(loss.item(), 4))\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        denoised = np.clip(model(noisy_images).detach().cpu().numpy()[0, 0], 0, 1).astype(np.float64)\n",
    "        clean=np.clip(clean_images.detach().cpu().numpy()[0, 0], 0, 1).astype(np.float64)\n",
    "        best_psnr = compare_psnr(denoised, clean)\n",
    "        best_images.append(denoised)\n",
    "        print(\"\\tModel PSNR: \", np.round(best_psnr, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = DataLoader(test,\n",
    "                                              batch_size=50,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=3)\n",
    "i, test_batch = next(enumerate(test_data_loader))\n",
    "noisy, clean = test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_output = model(noisy)\n",
    "invariant_output = masker.infer_full_image(noisy, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 19\n",
    "plot_tensors([clean[idx], noisy[idx], simple_output[idx], invariant_output[idx]],\n",
    "            [\"Ground Truth\", \"Noisy Image\", \"Single Pass Inference\", \"J-Invariant Inference\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test loss, single pass: \", round(loss_function(clean, simple_output).item(), 3))\n",
    "print(\"Test loss, J-invariant: \", round(loss_function(clean, invariant_output).item(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "git_dir = \"{}/{}\".format(os.path.expandvars(os.environ.get('~/Notebooks')), os.path.expandvars(os.environ.get('Deep-Learning-Denoising')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~/Notebooks/Deep-Learning-Denoising'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-653bba11a830>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpandvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~/Notebooks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib64/python3.6/posixpath.py\u001b[0m in \u001b[0;36mexpandvars\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \"\"\"Expand shell variables of form $var and ${var}.  Unknown variables\n\u001b[1;32m    287\u001b[0m     are left unchanged.\"\"\"\n\u001b[0;32m--> 288\u001b[0;31m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_varprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_varprogb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "os.path.expandvars(os.environ.get(\"~/Notebooks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/wynton/home/huang/emaad/Notebooks\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv('GIT_PARENT_DIR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv('/wynton/home/huang/emaad/Norebooks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put(self):\n",
    "\n",
    "    # git parameters from environment variables\n",
    "\n",
    "    git_dir = \"{}/{}\".format(os.path.expandvars(os.environ.set('GIT_PARENT_DIR')), os.path.expandvars(os.environ.set('GIT_REPO_NAME')))\n",
    "    git_url = os.path.expandvars(os.environ.get('GIT_REMOTE_URL'))\n",
    "    git_user = os.path.expandvars(os.environ.get('GIT_USER'))\n",
    "    git_repo_upstream = os.path.expandvars(os.environ.get('GIT_REMOTE_UPSTREAM'))\n",
    "    git_branch = git_remote = os.path.expandvars(os.environ.get('GIT_BRANCH_NAME'))\n",
    "    git_access_token = os.path.expandvars(os.environ.get('GITHUB_ACCESS_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=\"1\" + \"/\" + \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1/1'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_dir = \"{}/{}\".format(os.path.expandvars(os.environ.get('GIT_PARENT_DIR')), os.path.expandvars(os.environ.get('GIT_REPO_NAME')))\n",
    "git_url = os.path.expandvars(os.environ.get('GIT_REMOTE_URL'))\n",
    "git_user = os.path.expandvars(os.environ.get('GIT_USER'))\n",
    "git_repo_upstream = os.path.expandvars(os.environ.get('GIT_REMOTE_UPSTREAM'))\n",
    "git_branch = git_remote = os.path.expandvars(os.environ.get('GIT_BRANCH_NAME'))\n",
    "git_access_token = os.path.expandvars(os.environ.get('GITHUB_ACCESS_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'master'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/wynton/home/huang/emaad/Notebooks'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(git_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-0ee53525f0e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'filename' is not defined"
     ]
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/wynton/home/huang/emaad/Notebooks/Deep-Learning-Denoising'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ.get('GIT_PARENT_DIR') + \"/\" + os.environ.get('GIT_REPO_NAME') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-32-0898e432df54>, line 96)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-0898e432df54>\"\u001b[0;36m, line \u001b[0;32m96\u001b[0m\n\u001b[0;31m    route_pattern = ujoin(nbapp.settings['base_url'], '/git/commit')\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# expand variables since Docker's will pass VAR=$VAL as $VAL without expansion\n",
    "git_dir = \"{}/{}\".format(os.path.expandvars('GIT_PARENT_DIR'), os.path.expandvars('GIT_REPO_NAME'))\n",
    "git_url = os.path.expandvars(os.environ.get('GIT_REMOTE_URL'))\n",
    "git_user = os.path.expandvars(os.environ.get('GIT_USER'))\n",
    "git_repo_upstream = os.path.expandvars(os.environ.get('GIT_REMOTE_UPSTREAM'))\n",
    "git_branch = git_remote = os.path.expandvars(os.environ.get('GIT_BRANCH_NAME'))\n",
    "git_access_token = os.path.expandvars(os.environ.get('GITHUB_ACCESS_TOKEN'))\n",
    "\n",
    "# get the parent directory for git operations\n",
    "git_dir_parent = os.path.dirname(git_dir)\n",
    "\n",
    "# obtain filename and msg for commit\n",
    "data = json.loads(self.request.body.decode('utf-8'))\n",
    "filename = urllib.parse.unquote(data['filename'])\n",
    "msg = data['msg']\n",
    "commit_only_source = data['commit_only_source']\n",
    "\n",
    "\n",
    "# get current directory (to return later)\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# select branch within repo\n",
    "try:\n",
    "    os.chdir(git_dir)\n",
    "    dir_repo = check_output(['git','rev-parse','--show-toplevel']).strip()\n",
    "    repo = Repo(dir_repo.decode('utf8'))\n",
    "except GitCommandError as e:\n",
    "    self.error_and_return(cwd, \"Could not checkout repo: {}\".format(dir_repo))\n",
    "    return\n",
    "\n",
    "# create new branch\n",
    "try:\n",
    "    print(repo.git.checkout('HEAD', b=git_branch))\n",
    "except GitCommandError:\n",
    "    print(\"Switching to {}\".format(repo.heads[git_branch].checkout()))\n",
    "\n",
    "# commit current notebook\n",
    "# client will sent pathname containing git directory; append to git directory's parent\n",
    "try:\n",
    "    if commit_only_source :\n",
    "        subprocess.run(['jupyter', 'nbconvert', '--to', 'script', str(os.environ.get('GIT_PARENT_DIR') + \"/\" + os.environ.get('GIT_REPO_NAME') + filename)])\n",
    "        filename = str(os.environ.get('GIT_PARENT_DIR') + \"/\" + os.environ.get('GIT_REPO_NAME') + filename.replace('ipynb', 'py'))\n",
    "\n",
    "    print(repo.git.add(str(os.environ.get('GIT_PARENT_DIR') + \"/\" + os.environ.get('GIT_REPO_NAME') + filename)))\n",
    "    print(repo.git.commit( a=False, m=\"{}\\n\\nUpdated {}\".format(msg, filename) ))\n",
    "\n",
    "except GitCommandError as e:\n",
    "    print(e)\n",
    "    self.error_and_return(cwd, \"Could not commit changes to notebook: {}\".format(git_dir_parent + filename))\n",
    "    return\n",
    "\n",
    "# create or switch to remote\n",
    "try:\n",
    "    remote = repo.create_remote(git_remote, git_url)\n",
    "except GitCommandError:\n",
    "    print(\"Remote {} already exists...\".format(git_remote))\n",
    "    remote = repo.remote(git_remote)\n",
    "\n",
    "# push changes\n",
    "try:\n",
    "    pushed = remote.push(git_branch)\n",
    "    assert len(pushed)>0\n",
    "    assert pushed[0].flags in [git.remote.PushInfo.UP_TO_DATE, git.remote.PushInfo.FAST_FORWARD, git.remote.PushInfo.NEW_HEAD, git.remote.PushInfo.NEW_TAG]\n",
    "except GitCommandError as e:\n",
    "    print(e)\n",
    "    self.error_and_return(cwd, \"Could not push to remote {}\".format(git_remote))\n",
    "    return\n",
    "except AssertionError as e:\n",
    "    self.error_and_return(cwd, \"Could not push to remote {}: {}\".format(git_remote, pushed[0].summary))\n",
    "    return\n",
    "\n",
    "# open pull request\n",
    "try:\n",
    "  github_url = \"https://api.github.com/repos/{}/pulls\".format(git_repo_upstream)\n",
    "  github_pr = {\n",
    "      \"title\":\"{} Notebooks\".format(git_user),\n",
    "      \"body\":\"IPython notebooks submitted by {}\".format(git_user),\n",
    "      \"head\":\"{}:{}\".format(git_user, git_remote),\n",
    "      \"base\":\"master\"\n",
    "  }\n",
    "  github_headers = {\"Authorization\": \"token {}\".format(git_access_token)}\n",
    "  r = requests.post(github_url, data=json.dumps(github_pr), headers=github_headers)\n",
    "  if r.status_code != 201:\n",
    "    print(\"Error submitting Pull Request to {}\".format(git_repo_upstream))\n",
    "except:\n",
    "    print(\"Error submitting Pull Request to {}\".format(git_repo_upstream))\n",
    "\n",
    "# return to directory\n",
    "os.chdir(cwd)\n",
    "\n",
    "# close connection\n",
    "self.write({'status': 200, 'statusText': 'Success!  Changes to {} captured on branch {} at {}'.format(filename, git_branch, git_url)})\n",
    "\n",
    "\n",
    "def setup_handlers(nbapp):\n",
    "route_pattern = ujoin(nbapp.settings['base_url'], '/git/commit')\n",
    "nbapp.add_handlers('.*', [(route_pattern, GitCommitHandler)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/wynton/home/huang/emaad/Notebooks'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_dir_parent = os.path.dirname(git_dir)\n",
    "git_dir_parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-0ee53525f0e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'filename' is not defined"
     ]
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-8f5673a7453a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data = json.loads(self.request.body.decode('utf-8'))\n",
    "filename = urllib.parse.unquote(data['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParseResult(scheme='http', netloc='localhost:8892', path='/notebooks/Deep-Learning-Denoising/Deep-Notebook.ipynb', params='', query='', fragment='')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "urlparse(\"http://localhost:8892/notebooks/Deep-Learning-Denoising/Deep-Notebook.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
