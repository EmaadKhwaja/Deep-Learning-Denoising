{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T06:42:27.269385Z",
     "start_time": "2020-05-01T06:42:27.264427Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=50\n",
    "CROP_SIZE=256\n",
    "\n",
    "TRAIN_DATA_PATH = \"./Confocal_BPAE_B/raw\"\n",
    "GT_DATA_PATH = \"./Confocal_BPAE_B/gt\"\n",
    "NOISE_WEIGHT = .6\n",
    "\n",
    "VALIDATION_PCT = .2\n",
    "RANDOM_SEED = 42\n",
    "SHUFFLE_DATASET = False\n",
    "\n",
    "ITERATIONS=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T06:42:27.880789Z",
     "start_time": "2020-05-01T06:42:27.830555Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from numpy import inf\n",
    "from skimage.metrics import structural_similarity as ssm\n",
    "from scipy.special import factorial\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "import torch.nn as nn\n",
    "from torch.nn import MSELoss\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as f\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "from util import show, plot_images, plot_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T06:42:28.454339Z",
     "start_time": "2020-05-01T06:42:28.430195Z"
    }
   },
   "outputs": [],
   "source": [
    "class gtmatch():\n",
    "    def __init__(self, dataset1, dataset2, batch_size):\n",
    "        self.dataset1 = dataset1\n",
    "        self.dataset2 = dataset2\n",
    "        self.batch_size=batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.dataset1[index][0]\n",
    "        y = self.dataset2[int(index / self.batch_size % self.batch_size)][0]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset1)\n",
    "    \n",
    "  \n",
    "\n",
    "class log_funcs():\n",
    "    def __init__(self, updated, noise_ref):\n",
    "        self.updated=updated\n",
    "        self.noise_ref=noise_ref\n",
    "\n",
    "    def poisson_log(Ax, b):\n",
    "        # from https://stanford.edu/class/ee367/reading/lecture10_notes.pdf\n",
    "        term1 = np.log(Ax)*b\n",
    "        term2 = Ax\n",
    "        term3 = torch.from_numpy(np.log(factorial(b)))\n",
    "        \n",
    "        loglikelihood = term1 - term2 - term3\n",
    "        loglikelihood[np.isnan(loglikelihood)==True]=-10000000\n",
    "        loglikelihood[np.isinf(loglikelihood)==True]=-10000000\n",
    "        return loglikelihood[0]\n",
    "    \n",
    "    def gradient(updated, noise_ref):\n",
    "        grad_ll = []\n",
    "        zero_matrix = torch.zeros([noise_ref.shape[2], noise_ref.shape[3]], dtype=torch.double)\n",
    "        \n",
    "        ll_sum=zero_matrix.detach()\n",
    "        llh_sum=zero_matrix.detach()\n",
    "\n",
    "        for i, b in enumerate(noise_ref):\n",
    "            x = updated[i]\n",
    "            x_plus = updated[i]+.0001\n",
    "            Ax = add_noise(x,NOISE_WEIGHT,'Poisson')\n",
    "            Ax_plus = add_noise(x_plus,NOISE_WEIGHT,'Poisson')\n",
    "            \n",
    "                               \n",
    "            \n",
    "            # Poisson log-likelihood\n",
    "            loglikelihood = log_funcs.poisson_log(Ax, b)\n",
    "            loglikelihood_plus = log_funcs.poisson_log(Ax_plus, b)\n",
    "\n",
    "        \n",
    "            grad=(loglikelihood_plus-loglikelihood)/.0001\n",
    "            grad_ll.append(grad)\n",
    "            \n",
    "        return torch.stack(grad_ll).unsqueeze(1).float()\n",
    "\n",
    "\n",
    "        \n",
    "def add_noise(clean_images,noise_weight,noise_type):\n",
    "    clean_np = np.clip(clean_images.detach().numpy(),0,1)\n",
    "\n",
    "    if 'Poisson' in noise_type:\n",
    "        noise_mask = np.random.poisson(clean_np)\n",
    "    else:\n",
    "        noise_mask= clean_np*0\n",
    "\n",
    "    noisy_images = torch.clamp(torch.from_numpy(clean_np+(noise_mask*noise_weight)),0,1).float() \n",
    "    return noisy_images\n",
    "\n",
    "\n",
    "def live_plot(data, figsize=(7,5), title=''):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(data)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Iteration')\n",
    "    clear_output(wait=True)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T06:42:28.896638Z",
     "start_time": "2020-05-01T06:42:28.818476Z"
    },
    "code_folding": [
     38
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class InputRNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_cell=None, input_fun=None):\n",
    "        super(InputRNN, self).__init__()\n",
    "\n",
    "        self.rnn_cell = rnn_cell\n",
    "        self.input_fun = input_fun\n",
    "\n",
    "    def forward(self, x, hx=None):\n",
    "\n",
    "        if self.input_fun is not None:\n",
    "            x = self.input_fun.forward(x)\n",
    "        if self.rnn_cell is not None:\n",
    "            x = self.rnn_cell.forward(x)\n",
    "            hx = x\n",
    "\n",
    "        return x, hx\n",
    "\n",
    "class ConvNonlinear(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, features, conv_dim, kernel_size, dilation, bias, nonlinear='relu'):\n",
    "        super(ConvNonlinear, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.features = features\n",
    "        self.bias = bias\n",
    "        self.conv_dim = conv_dim\n",
    "        self.conv_class = self.determine_conv_class(conv_dim)\n",
    "        if nonlinear is not None and nonlinear.upper() == 'RELU':\n",
    "            self.nonlinear = torch.nn.ReLU()\n",
    "        elif nonlinear is None:\n",
    "            self.nonlinear = lambda x: x\n",
    "        else:\n",
    "            ValueError('Please specify a proper')\n",
    "\n",
    "        self.padding = [torch.nn.ReplicationPad1d(dilation * (kernel_size-1) // 2),\n",
    "                        torch.nn.ReplicationPad2d(dilation * (kernel_size-1) // 2),\n",
    "                        torch.nn.ReplicationPad3d(dilation * (kernel_size - 1) // 2)][conv_dim-1]\n",
    "        self.conv_layer =  self.conv_class(in_channels=input_size, out_channels=features,\n",
    "                             kernel_size=kernel_size, padding=0,\n",
    "                             dilation=dilation, bias=bias)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.kaiming_normal_(self.conv_layer.weight, nonlinearity='relu')\n",
    "\n",
    "        if self.conv_layer.bias is not None:\n",
    "            nn.init.zeros_(self.conv_layer.bias)\n",
    "\n",
    "    def determine_conv_class(self, n_dim):\n",
    "\n",
    "        if n_dim is 1:\n",
    "            return nn.Conv1d\n",
    "        elif n_dim is 2:\n",
    "            return nn.Conv2d\n",
    "        elif n_dim is 3:\n",
    "            return nn.Conv3d\n",
    "        else:\n",
    "            NotImplementedError(\"No convolution of this dimensionality implemented\")\n",
    "\n",
    "    def extra_repr(self):\n",
    "        s = '{input_size}, {features}'\n",
    "        if 'bias' in self.__dict__ and self.bias is not True:\n",
    "            s += ', bias={bias}'\n",
    "        if 'nonlinear' in self.__dict__ and self.nonlinear != \"tanh\":\n",
    "            s += ', nonlinearity={nonlinear}'\n",
    "        return s.format(**self.__dict__)\n",
    "\n",
    "    def check_forward_input(self, input):\n",
    "        if input.size(1) != self.input_size:\n",
    "            raise RuntimeError(\n",
    "                \"input has inconsistent input_size: got {}, expected {}\".format(\n",
    "                    input.size(1), self.input_size))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.nonlinear(self.conv_layer(self.padding(input)))\n",
    "\n",
    "\n",
    "class ConvRNNCellBase(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_chunks, conv_dim, kernel_size,\n",
    "                dilation, bias):\n",
    "        super(ConvRNNCellBase, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        self.num_chunks = num_chunks\n",
    "        self.conv_dim = conv_dim\n",
    "        self.conv_class = self.determine_conv_class(conv_dim)\n",
    "        self.ih = self.conv_class(in_channels=input_size, out_channels=num_chunks*hidden_size,\n",
    "                             kernel_size=kernel_size, padding=dilation * (kernel_size-1)//2,\n",
    "                             dilation=dilation, bias=bias)\n",
    "        self.hh = self.conv_class(in_channels=hidden_size, out_channels=num_chunks*hidden_size,\n",
    "                             kernel_size=kernel_size, padding=dilation * (kernel_size-1)//2,\n",
    "                             dilation=dilation, bias=bias)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "\n",
    "        self.ih.weight.data = self.orthotogonalize_weights(self.ih.weight.data)\n",
    "        self.hh.weight.data = self.orthotogonalize_weights(self.hh.weight.data)\n",
    "\n",
    "        if self.bias is True:\n",
    "            nn.init.zeros_(self.ih.bias)\n",
    "            nn.init.zeros_(self.hh.bias)\n",
    "\n",
    "    def orthotogonalize_weights(self, weights, chunks=1):\n",
    "        return torch.cat([nn.init.orthogonal_(w) for w in weights.chunk(chunks,0)],0)\n",
    "\n",
    "    def determine_conv_class(self, n_dim):\n",
    "\n",
    "        if n_dim is 1:\n",
    "            return nn.Conv1d\n",
    "        elif n_dim is 2:\n",
    "            return nn.Conv2d\n",
    "        elif n_dim is 3:\n",
    "            return nn.Conv3d\n",
    "        else:\n",
    "            NotImplementedError(\"No convolution of this dimensionality implemented\")\n",
    "\n",
    "    def extra_repr(self):\n",
    "        s = '{input_size}, {hidden_size}'\n",
    "        if 'bias' in self.__dict__ and self.bias is not True:\n",
    "            s += ', bias={bias}'\n",
    "        if 'nonlinearity' in self.__dict__ and self.nonlinearity != \"tanh\":\n",
    "            s += ', nonlinearity={nonlinearity}'\n",
    "        return s.format(**self.__dict__)\n",
    "\n",
    "    def check_forward_input(self, input):\n",
    "        if input.size(1) != self.input_size:\n",
    "            raise RuntimeError(\n",
    "                \"input has inconsistent input_size: got {}, expected {}\".format(\n",
    "                    input.size(1), self.input_size))\n",
    "\n",
    "    def check_forward_hidden(self, input, hx, hidden_label=''):\n",
    "        if input.size(0) != hx.size(0):\n",
    "            raise RuntimeError(\n",
    "                \"Input batch size {} doesn't match hidden{} batch size {}\".format(\n",
    "                    input.size(0), hidden_label, hx.size(0)))\n",
    "\n",
    "        if hx.size(1) != self.hidden_size:\n",
    "            raise RuntimeError(\n",
    "                \"hidden{} has inconsistent hidden_size: got {}, expected {}\".format(\n",
    "                    hidden_label, hx.size(1), self.hidden_size))\n",
    "\n",
    "\n",
    "class ConvGRUCell(ConvRNNCellBase):\n",
    "    \"\"\"\n",
    "    This is an implementation of a Convolutional GRU Cell following the Pytorch implementation\n",
    "    of a GRU. Here, the fully connected linear transforms are simply replaced by convolutional\n",
    "    linear transforms.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, conv_dim, kernel_size, dilation=1, bias=True):\n",
    "        super(ConvGRUCell, self).__init__(input_size=input_size, hidden_size=hidden_size,\n",
    "                                          num_chunks=3, conv_dim=conv_dim, kernel_size=kernel_size,\n",
    "                                          dilation=dilation, bias=bias)\n",
    "\n",
    "    def forward(self, input, hx=None):\n",
    "        # self.check_forward_input(input)\n",
    "        if hx is None:\n",
    "            hx = input.new_zeros((input.size(0), self.hidden_size) + input.size()[2:],\n",
    "                                 requires_grad=False)\n",
    "        # self.check_forward_hidden(input, hx)\n",
    "\n",
    "        ih = self.ih(input).chunk(3,dim=1)\n",
    "        hh = self.hh(hx).chunk(3,dim=1)\n",
    "\n",
    "        z = torch.sigmoid(ih[0] + hh[0])\n",
    "        r = torch.sigmoid(ih[1] + hh[1])\n",
    "        n = torch.tanh(ih[2] + r*hh[2])\n",
    "\n",
    "        hx = (1. - z) * hx + z * n\n",
    "\n",
    "        return hx\n",
    "\n",
    "class ConvRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size,\n",
    "                 conv_params={'features':[64, 64, 2], 'k_size':[5, 3, 3],'dilation':[1, 2, 1],'bias':[True,True,False],\n",
    "                              'nonlinear':['relu','relu',None]},\n",
    "                 rnn_params={'features':[64, 64, 0], 'k_size':[1, 1, 0], 'dilation':[1, 1, 0], 'bias': [True,True, False],\n",
    "                             'rnn_type': ['gru','gru',None]},\n",
    "                 conv_dim=2):\n",
    "        '''\n",
    "        Generates a multi-layer convolutional GRU.\n",
    "        Preserves spatial dimensions across cells, only altering depth.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_size : integer. depth dimension of input tensors.\n",
    "        hidden_sizes : integer or list. depth dimensions of hidden state.\n",
    "            if integer, the same hidden size is used for all cells.\n",
    "        kernel_sizes : integer or list. sizes of Conv2d gate kernels.\n",
    "            if integer, the same kernel size is used for all cells.\n",
    "        n_layers : integer. number of chained `ConvGRUCell`.\n",
    "        '''\n",
    "\n",
    "        super(ConvRNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.conv_dim = conv_dim\n",
    "        self.conv_params = conv_params\n",
    "        self.rnn_params = rnn_params\n",
    "\n",
    "        conv_params = zip(*(conv_params[k] for k in ['features', 'k_size', 'dilation', 'bias', 'nonlinear']))\n",
    "        rnn_params = zip(*(rnn_params[k] for k in ['features', 'k_size', 'dilation', 'bias', 'rnn_type']))\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for (conv_features, conv_k_size, conv_dilation, conv_bias, nonlinear), \\\n",
    "            (rnn_features, rnn_k_size, rnn_dilation, rnn_bias, rnn_type) in zip(conv_params, rnn_params):\n",
    "            conv_layer = None\n",
    "            rnn_layer = None\n",
    "\n",
    "            if conv_features > 0:\n",
    "                conv_layer = ConvNonlinear(input_size, conv_features, conv_dim=self.conv_dim,\n",
    "                                           kernel_size=conv_k_size, dilation=conv_dilation, bias=conv_bias,\n",
    "                                           nonlinear=nonlinear)\n",
    "                input_size = conv_features\n",
    "\n",
    "            if rnn_features > 0 and rnn_type is not None:\n",
    "                if rnn_type.upper() == 'GRU':\n",
    "                    rnn_type = ConvGRUCell\n",
    "                elif issubclass(rnn_type, ConvRNNCellBase):\n",
    "                    rnn_type = rnn_type\n",
    "                else:\n",
    "                    ValueError('Please speacify a proper rrn_type')\n",
    "\n",
    "                rnn_layer = rnn_type(input_size, rnn_features, conv_dim=self.conv_dim,\n",
    "                                          kernel_size=rnn_k_size, dilation=rnn_dilation, bias=rnn_bias)\n",
    "                input_size = rnn_features\n",
    "\n",
    "            self.layers.append(InputRNN(rnn_layer, conv_layer))\n",
    "\n",
    "    def forward(self, input, hx=None):\n",
    "        if not hx:\n",
    "            hx = [None]*len(self.layers)\n",
    "\n",
    "        hidden_new = []\n",
    "\n",
    "        for layer, local_hx in zip(self.layers,hx):\n",
    "            input, new_hx = layer.forward(input, local_hx)\n",
    "            hidden_new.append(new_hx)\n",
    "\n",
    "        return input, hidden_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T06:42:29.796333Z",
     "start_time": "2020-05-01T06:42:29.785425Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class RIM(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn, grad_fun):\n",
    "        super(RIM, self).__init__()\n",
    "        self.rnn = rnn\n",
    "        self.grad_fun = grad_fun\n",
    "\n",
    "    def forward(self, eta, data, hx=None, n_steps=1, accumulate_eta=False):\n",
    "        \"\"\"\n",
    "        :param eta: Starting value for eta [n_batch,features,height,width]\n",
    "        :param grad_fun: The gradient function, takes as input eta and outputs gradient of same dimensionality\n",
    "        :param hx: Hidden state of the RNN\n",
    "        :param n_steps: Number of time steps, that the RIM should perform. Default: 1\n",
    "        :param accumulate_eta: Bool, if True will save all intermediate etas in a list, else outputs only the last eta.\n",
    "                               Default: False\n",
    "        :return: etas, hx\n",
    "        \"\"\"\n",
    "        etas = []\n",
    "\n",
    "        for i in range(n_steps):\n",
    "            \n",
    "                        \n",
    "            eta=eta.permute(1,0,2,3)[0].unsqueeze(1)\n",
    "            grad_eta = self.grad_fun(eta, data)\n",
    "            x_in = torch.cat((eta, grad_eta), 1)\n",
    "\n",
    "            delta, hx = self.rnn.forward(x_in, hx)\n",
    "            eta = eta + delta\n",
    "\n",
    "            if accumulate_eta:\n",
    "                etas.append(eta)\n",
    "\n",
    "        if not accumulate_eta:\n",
    "            etas = eta\n",
    "\n",
    "        return etas, hx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T06:42:30.507709Z",
     "start_time": "2020-05-01T06:42:30.504583Z"
    }
   },
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T06:42:31.143500Z",
     "start_time": "2020-05-01T06:42:31.095869Z"
    }
   },
   "outputs": [],
   "source": [
    "# load and sort dataset\n",
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.CenterCrop(CROP_SIZE),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(\n",
    "    root=TRAIN_DATA_PATH, transform=TRANSFORM_IMG)\n",
    "gt_data = torchvision.datasets.ImageFolder(\n",
    "    root=GT_DATA_PATH, transform=TRANSFORM_IMG)\n",
    "\n",
    "newdataset = gtmatch(train_data, gt_data, BATCH_SIZE)\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(newdataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(VALIDATION_PCT * dataset_size))\n",
    "\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "if SHUFFLE_DATASET:\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    np.random.shuffle(train_indices)\n",
    "    np.random.shuffle(val_indices)\n",
    "\n",
    "    \n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SequentialSampler(train_indices)\n",
    "valid_sampler = SequentialSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    newdataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(newdataset, batch_size=BATCH_SIZE,\n",
    "                                                sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T06:42:31.919574Z",
     "start_time": "2020-05-01T06:42:31.725541Z"
    }
   },
   "outputs": [],
   "source": [
    "step_models=ConvRNN(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T06:42:32.242787Z",
     "start_time": "2020-05-01T06:42:32.225957Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grad_fun=log_funcs.gradient\n",
    "model = RIM(step_models,grad_fun)\n",
    "model = model.to(device)\n",
    "loss_function = MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T06:46:42.262657Z",
     "start_time": "2020-05-01T06:42:32.955569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/wynton/home/huang/emaad/.local/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2516582400 bytes. Error code 12 (Cannot allocate memory)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b5138d6ee7a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoisy_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mITERATIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a584176942d6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, eta, data, hx, n_steps, accumulate_eta)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mx_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_eta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-16693c7a80ac>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_hx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_hx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_hx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0mhidden_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_hx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-16693c7a80ac>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hx)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_cell\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-16693c7a80ac>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# self.check_forward_hidden(input, hx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mih\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mih\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mhh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2516582400 bytes. Error code 12 (Cannot allocate memory)\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "avg_grad_logs = []\n",
    "val_losses = []\n",
    "best_val_loss = 1\n",
    "loss = 'null'\n",
    "\n",
    "data_loader = train_loader\n",
    "\n",
    "\n",
    "for i, batch in enumerate(data_loader):\n",
    "    print(i)\n",
    "    clean_images, gt = batch\n",
    "\n",
    "    noise=torch.distributions.poisson.Poisson(clean_images.detach()).sample()*NOISE_WEIGHT\n",
    "    gaussian=torch.randn(clean_images.size())*NOISE_WEIGHT\n",
    "    noisy_images=clean_images+noise\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    model.zero_grad()\n",
    "    \n",
    "    eta=torch.zeros(clean_images.shape)\n",
    "    hx=torch.zeros(clean_images.shape)\n",
    "    \n",
    "    \n",
    "\n",
    "    eta, hx = model.forward(eta,noisy_images, n_steps=ITERATIONS)\n",
    "    loss = torch.nn.functional.mse_loss(eta, clean_images)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    live_plot(losses,title=loss.item())\n",
    "    plot_tensors(eta)\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
