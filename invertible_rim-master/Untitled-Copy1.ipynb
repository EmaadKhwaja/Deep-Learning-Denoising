{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T04:25:23.133132Z",
     "start_time": "2020-05-01T04:25:22.946337Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 480.00 MiB (GPU 0; 5.94 GiB total capacity; 640.39 MiB already allocated; 153.44 MiB free; 994.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-25da7b267c02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m# Initial states of the IRIM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0mx_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mim_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconv_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0mx_test_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mim_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconv_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mx_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 480.00 MiB (GPU 0; 5.94 GiB total capacity; 640.39 MiB already allocated; 153.44 MiB free; 994.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A simple demonstration for training an IRIM as an image denoiser.\n",
    "\n",
    "This script will lead through the process of defining a gradient function for the IRIM, then\n",
    "building the RIM model, and how to train the model using invert to learn. This script will utilize\n",
    "CUDA devices if available.\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "from irim import IRIM\n",
    "from irim import InvertibleUnet\n",
    "from irim import MemoryFreeInvertibleModule\n",
    "\n",
    "# Use CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---- Parameters ---\n",
    "# Working with images, for time series or volumes set to 1 or 3, respectively\n",
    "conv_nd = 2\n",
    "# Number of Householder projections for constructing 1x1 convolutions\n",
    "n_householder = 3\n",
    "# Number of channels for each layer of the Invertible Unet\n",
    "n_channels = [16,8,4,8,16]\n",
    "# Number of hidden channel in the residual functions of the Invertible Unet\n",
    "n_hidden = [16] * 5\n",
    "# Downsampling factors\n",
    "dilations = [1,2,4,2,1]\n",
    "# Number of IRIM steps\n",
    "n_steps = 5\n",
    "# Number of image channels\n",
    "im_channels = 1\n",
    "# Number of total samples\n",
    "n_samples = 64\n",
    "im_size = 512\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "def grad_fun(x_est,y):\n",
    "    \"\"\"\n",
    "    Defines the gradient function for a denoising problem with White Noise.\n",
    "\n",
    "    This function demonstrates the use of  Pytorch's autograd to calculate the gradient.\n",
    "    In this example, the function is equivalent to\n",
    "\n",
    "    def grad_fun(x_est,y):\n",
    "        return x_est - y\n",
    "\n",
    "    :param x_est: Tensor, model estimate of x\n",
    "    :param y: Tensor, noisy measurements\n",
    "    :return: grad_x\n",
    "    \"\"\"\n",
    "    # True during training, False during testing\n",
    "    does_require_grad = x_est.requires_grad\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        # Necessary for using autograd\n",
    "        x_est.requires_grad_(True)\n",
    "        # Assuming uniform white noise, in the denoising case matrix A is the identity\n",
    "        error = torch.sum((y - x_est)**2)\n",
    "        # We retain the graph during training only\n",
    "        grad_x = torch.autograd.grad(error, inputs=x_est, retain_graph=does_require_grad,\n",
    "                                     create_graph=does_require_grad)[0]\n",
    "    # Set requires_grad back to it's original state\n",
    "    x_est.requires_grad_(does_require_grad)\n",
    "\n",
    "    return grad_x\n",
    "\n",
    "# def grad_fun(x_est, y):\n",
    "#     return x_est - y\n",
    "# At every iteration of the IRIM we use an Invertible Unet for processing. Note, that the use of ModuleList\n",
    "# is necessary for Pytorch to properly register all modules.\n",
    "step_models = torch.nn.ModuleList([InvertibleUnet(n_channels=n_channels,n_hidden=n_hidden,dilations=dilations,\n",
    "                                   conv_nd=conv_nd, n_householder=n_householder) for i in range(n_steps)])\n",
    "\n",
    "# Build IRIM\n",
    "model = IRIM(step_models,grad_fun,im_channels)\n",
    "# Wrap the model to be trained with invert to learn\n",
    "model = MemoryFreeInvertibleModule(model)\n",
    "model.to(device)\n",
    "# Use DataParallel if multiple devices are available\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "\n",
    "# We generate a simple toy data set where the ground truth data has the same values in the image\n",
    "# dimensions but different values across batch and channel dimensions. This demonstrates that the\n",
    "# IRIM can deal with the implicit structure in the data, with a high range of values, and it can even\n",
    "# do extrapolation.\n",
    "x = torch.ones(n_samples,im_channels,*[im_size]*conv_nd, requires_grad=False, device=device)\n",
    "x = torch.cumsum(x,0)\n",
    "x = torch.cumsum(x,1)\n",
    "y = x + torch.randn_like(x)\n",
    "\n",
    "# Training and test split. This will result un an extrapolation problem on the test set.\n",
    "y, y_test = torch.chunk(y,2,0)\n",
    "x, x_test = torch.chunk(x,2,0)\n",
    "\n",
    "# Initial states of the IRIM\n",
    "x_in = torch.cat((y,torch.zeros(y.size(0),n_channels[0]-im_channels,*[im_size]*conv_nd, device=device)),1)\n",
    "x_test_in = torch.cat((y_test,torch.zeros(y_test.size(0),n_channels[0]-im_channels,*[im_size]*conv_nd, device=device)),1)\n",
    "x_in.requires_grad_(True)\n",
    "x_test_in.requires_grad_(False)\n",
    "\n",
    "for i in range(3000):\n",
    "    optimizer.zero_grad()\n",
    "    model.zero_grad()\n",
    "\n",
    "    # We only regress on the image dimensions\n",
    "    x_est = model.forward(x_in, y)[:,:im_channels]\n",
    "    loss = torch.nn.functional.mse_loss(x_est, x)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x_est = model.forward(x_test_in, y_test)[:, :im_channels]\n",
    "            loss = torch.nn.functional.mse_loss(x_est, x_test)\n",
    "            loss_noisy = torch.nn.functional.mse_loss(y_test, x_test)\n",
    "        print('Iteration', i, ': test loss =',loss.item(), ' loss noisy image =',loss_noisy.item())\n",
    "        model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
